{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ceerogreen/DS2002Final/blob/main/DS_2002_Final_Project_ETL_and_GoogleCloud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import libraries**"
      ],
      "metadata": {
        "id": "np0c1d1APw-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymongo\n",
        "!pip install google-cloud-bigquery\n",
        "\n",
        "import pandas as pd\n",
        "from pymongo import MongoClient\n",
        "from google.cloud import bigquery\n",
        "from google.colab import auth\n",
        "import csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ND_VoT0DP4bQ",
        "outputId": "440e47c0-832c-45af-d738-ab0bd1410d0d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (4.10.1)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo) (2.7.0)\n",
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.10/dist-packages (3.25.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (2.19.2)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.27.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.7.2)\n",
            "Requirement already satisfied: packaging>=20.0.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (24.2)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.8.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery) (2.32.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.66.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (4.25.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.25.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.68.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery) (1.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2024.8.30)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cleaning Tables**"
      ],
      "metadata": {
        "id": "m90WpHRwOJhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_2020 = pd.read_csv('/content/2020EAVSData.csv')\n",
        "data_2016 = pd.read_csv('/content/2016EAVSData.csv')\n",
        "\n",
        "# Defining the columns to keep\n",
        "columns_2020 = [\n",
        "    'FIPSCode', 'Jurisdiction_Name', 'State_Full', 'State_Abbr',\n",
        "    'C1a', 'C1b', 'C1c', 'C1d', 'C1e', 'C1f', 'C1g_Other', 'C1g', 'C1h_Other', 'C1h',\n",
        "    'C1i_Other', 'C1i', 'C1Comments', 'C2a', 'C2Comments', 'C3a', 'C3Comments',\n",
        "    'C4a', 'C4b', 'C4c', 'C4d', 'C4e', 'C4f', 'C4g', 'C4h', 'C4i', 'C4j', 'C4k',\n",
        "    'C4l', 'C4m', 'C4n', 'C4o', 'C4p_Other', 'C4p', 'C4q_Other', 'C4q', 'C4r_Other',\n",
        "    'C4r', 'C4Comments'\n",
        "]\n",
        "\n",
        "columns_2016 = [\n",
        "    'FIPSCode', 'FIPS_2Digit', 'State', 'JurisdictionName',\n",
        "    'C1a', 'C1b', 'C1c', 'C1d', 'C1e', 'C1f_Other', 'C1f', 'C1g_Other', 'C1g',\n",
        "    'C1h_Other', 'C1h', 'C1Comments', 'C2', 'C2Comments', 'C3', 'C3Comments',\n",
        "    'C4a', 'C4b', 'C4c_Other', 'C4c', 'C4d_Other', 'C4d', 'C4Comments', 'C5a',\n",
        "    'C5b', 'C5c', 'C5d', 'C5e', 'C5f', 'C5g', 'C5h', 'C5i', 'C5j', 'C5k', 'C5l',\n",
        "    'C5m', 'C5n', 'C5o_Other', 'C5o', 'C5p_Other', 'C5p', 'C5q_Other', 'C5q',\n",
        "    'C5r_Other', 'C5r', 'C5s_Other', 'C5s', 'C5t_Other', 'C5t', 'C5u_Other',\n",
        "    'C5u', 'C5v_Other', 'C5v', 'C5Comments'\n",
        "]\n",
        "\n",
        "# Keeping only the specified columns\n",
        "new_2020 = data_2020[columns_2020]\n",
        "new_2016 = data_2016[columns_2016]\n",
        "\n",
        "new_2020.to_csv('Cleaned_2020EAVSData.csv', index=False)\n",
        "new_2016.to_csv('Cleaned_2016EAVSData.csv', index=False)\n",
        "\n",
        "print(\"Datasets cleaned and saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KLKIBb9OJOF",
        "outputId": "5d6cb804-3328-4ccb-a7df-36c3d58f9ccf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-29295a9b881a>:2: DtypeWarning: Columns (4,7,8,9,11,12,14,15,16,17,18,21,22,24,25,26,27,29,31,34,35,36,42,44,46,48,49,51,53,65,67,69,71,73,75,87,89,91,93,95,97,109,111,113,115,117,119,127,129,131,141,143,145,147,150,151,152,153,155,157,158,159,160,161,163,164,165,166,168,170,173,177,181,185,187,188,189,190,191,192,194,195,196,198,199,200,204,206,207,208,209,210,213,214,216,219,220,221,223,224,225,227,228,229,233,235,236,237,238,239,240,242,243,244,245,246,250,251,252,253,255,258,259,266,268,269,271,274,276,278,280,281,283,285,287,289,290,291,292,293,299,302,303,304,305,306,307,308,309,313,314,316,317,318,319,325,332,333,335,337,339,341,343,345,346,347,348,349,350,351,353,354,355,357,359,361,362,364,368,373,375,377,378,379,380,382,383,386,387,388,390,391,392,394,395,396,398,400,401,402,404,406,408,409,410,414,416,418,421,423,425,428,429,430,432,433,434,436,437,438,440,441,442,444,447,449,452,453,454,456,457,458,460,461,462,464,465,466,468,469,474,475,476,477,479,480,481,483,484,485,487,488,489,491,492,493,495,496,498,500,501,502,503,505,506,507,509,510,511,513,514,515,517,520,521,522,524,525,526,528,529,530,532,533,534,536,537,538,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data_2016 = pd.read_csv('/content/2016EAVSData.csv')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets cleaned and saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Replacing -888888 in the 2016 dataset and -88 in the 2020 dataset with NA**"
      ],
      "metadata": {
        "id": "5Z4RByo3P9lv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_2020 = pd.read_csv('Cleaned_2020EAVSData.csv')\n",
        "cleaned_2016 = pd.read_csv('Cleaned_2016EAVSData.csv')\n",
        "\n",
        "cleaned_2020.replace(-88, pd.NA, inplace=True)\n",
        "cleaned_2016.replace('-888888: Not Applicable', pd.NA, inplace=True)\n",
        "\n",
        "cleaned_2020.to_csv('Updated_Cleaned_2020EAVSData.csv', index=False)\n",
        "cleaned_2016.to_csv('Updated_Cleaned_2016EAVSData.csv', index=False)\n",
        "\n",
        "print(\"Special codes replaced with NA successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-boFdaRT6iqB",
        "outputId": "cdf10dd1-354a-466a-ebf6-904d88364248"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Special codes replaced with NA successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Replacing -999999 in the 2016 dataset and -99 in the 2020 dataset with No Data**"
      ],
      "metadata": {
        "id": "anL1CgliSG1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_2020 = pd.read_csv('Updated_Cleaned_2020EAVSData.csv')\n",
        "cleaned_2016 = pd.read_csv('Updated_Cleaned_2016EAVSData.csv')\n",
        "\n",
        "cleaned_2020.replace(-99, \"No Data\", inplace=True)\n",
        "cleaned_2016.replace(\"-999999: Data Not Available\", \"No Data\", inplace=True)\n",
        "\n",
        "cleaned_2020.to_csv('Final_Cleaned_2020EAVSData.csv', index=False)\n",
        "cleaned_2016.to_csv('Final_Cleaned_2016EAVSData.csv', index=False)\n",
        "\n",
        "print(\"Special codes replaced with 'No Data' successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LWqOlpiSHdL",
        "outputId": "8cd3274e-b6aa-4add-bf61-fd92ab5d060c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Special codes replaced with 'No Data' successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_2020 = pd.read_csv('Final_Cleaned_2020EAVSData.csv')\n",
        "cleaned_2016 = pd.read_csv('Final_Cleaned_2016EAVSData.csv')\n",
        "\n",
        "# Displaying the first few rows to check cleaning results\n",
        "print(\"Preview of 2020 Dataset:\")\n",
        "print(cleaned_2020.head())\n",
        "\n",
        "print(\"\\nPreview of 2016 Dataset:\")\n",
        "print(cleaned_2016.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoO1f6pRTVIZ",
        "outputId": "63423b25-03df-4d89-84d1-3de234c3ee8f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preview of 2020 Dataset:\n",
            "    FIPSCode Jurisdiction_Name State_Full State_Abbr      C1a     C1b  \\\n",
            "0  100100000    AUTAUGA COUNTY    ALABAMA         AL   1329.0  1026.0   \n",
            "1  100300000    BALDWIN COUNTY    ALABAMA         AL  11147.0  9315.0   \n",
            "2  100500000    BARBOUR COUNTY    ALABAMA         AL    726.0   647.0   \n",
            "3  100700000       BIBB COUNTY    ALABAMA         AL    332.0   274.0   \n",
            "4  100900000     BLOUNT COUNTY    ALABAMA         AL   1032.0   828.0   \n",
            "\n",
            "       C1c      C1d   C1e      C1f  ...      C4m      C4n      C4o  \\\n",
            "0      0.0  No Data  26.0  No Data  ...  No Data  No Data  No Data   \n",
            "1     11.0  No Data   0.0  No Data  ...  No Data  No Data  No Data   \n",
            "2  No Data  No Data  11.0  No Data  ...  No Data  No Data  No Data   \n",
            "3      0.0  No Data   3.0  No Data  ...  No Data  No Data  No Data   \n",
            "4      0.0  No Data  13.0  No Data  ...  No Data  No Data  No Data   \n",
            "\n",
            "    C4p_Other   C4p   C4q_Other   C4q   C4r_Other   C4r C4Comments  \n",
            "0  VALID SKIP -77.0  VALID SKIP -77.0  VALID SKIP -77.0        NaN  \n",
            "1  VALID SKIP -77.0  VALID SKIP -77.0  VALID SKIP -77.0        NaN  \n",
            "2  VALID SKIP -77.0  VALID SKIP -77.0  VALID SKIP -77.0        NaN  \n",
            "3  VALID SKIP -77.0  VALID SKIP -77.0  VALID SKIP -77.0        NaN  \n",
            "4  VALID SKIP -77.0  VALID SKIP -77.0  VALID SKIP -77.0        NaN  \n",
            "\n",
            "[5 rows x 43 columns]\n",
            "\n",
            "Preview of 2016 Dataset:\n",
            "      FIPSCode  FIPS_2Digit State JurisdictionName    C1a    C1b  C1c  C1d  \\\n",
            "0  200000000.0            2    AK           ALASKA  31817  27626  680  167   \n",
            "1  100100000.0            1    AL   AUTAUGA COUNTY   1290   1207  NaN  NaN   \n",
            "2  100300000.0            1    AL   BALDWIN COUNTY   5317   4779  NaN  NaN   \n",
            "3  100500000.0            1    AL   BARBOUR COUNTY    652    611  NaN  NaN   \n",
            "4  100700000.0            1    AL      BIBB COUNTY    244    226  NaN  NaN   \n",
            "\n",
            "    C1e C1f_Other  ...      C5r C5s_Other      C5s C5t_Other      C5t  \\\n",
            "0  3344       NaN  ...  No Data       NaN  No Data       NaN  No Data   \n",
            "1   NaN       NaN  ...  No Data       NaN  No Data       NaN  No Data   \n",
            "2   NaN       NaN  ...  No Data       NaN  No Data       NaN  No Data   \n",
            "3   NaN       NaN  ...  No Data       NaN  No Data       NaN  No Data   \n",
            "4   NaN       NaN  ...  No Data       NaN  No Data       NaN  No Data   \n",
            "\n",
            "  C5u_Other      C5u C5v_Other      C5v C5Comments  \n",
            "0       NaN  No Data       NaN  No Data        NaN  \n",
            "1       NaN  No Data       NaN  No Data        NaN  \n",
            "2       NaN  No Data       NaN  No Data        NaN  \n",
            "3       NaN  No Data       NaN  No Data        NaN  \n",
            "4       NaN  No Data       NaN  No Data        NaN  \n",
            "\n",
            "[5 rows x 58 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Storing data set in MongoDB**"
      ],
      "metadata": {
        "id": "IyDCdnASAIet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_2020 = pd.read_csv('Final_Cleaned_2020EAVSData.csv')\n",
        "cleaned_2016 = pd.read_csv('Final_Cleaned_2016EAVSData.csv')\n",
        "\n",
        "connection_string = #REDACTED\n",
        "client = MongoClient(connection_string)\n",
        "\n",
        "db = client['eavs_db']\n",
        "\n",
        "# Inserting data into collections\n",
        "db.cleaned_2020.insert_many(cleaned_2020.to_dict('records'))\n",
        "db.cleaned_2016.insert_many(cleaned_2016.to_dict('records'))\n",
        "\n",
        "print(\"Data successfully loaded into MongoDB Atlas!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GKhB9PdAITw",
        "outputId": "af492922-ecb7-4987-a485-3c82d9b30800"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully loaded into MongoDB Atlas!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking for duplicates**"
      ],
      "metadata": {
        "id": "gSFhHz6z2N7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_2020 = pd.read_csv('Final_Cleaned_2020EAVSData.csv')\n",
        "cleaned_2016 = pd.read_csv('Final_Cleaned_2016EAVSData.csv')\n",
        "\n",
        "# Function to check for duplicates and insert only new data\n",
        "def insert_if_not_exists(collection_name, dataframe, unique_field):\n",
        "    collection = db[collection_name]\n",
        "\n",
        "    for record in dataframe.to_dict('records'):\n",
        "        # Check if the record already exists\n",
        "        if not collection.find_one({unique_field: record[unique_field]}):\n",
        "            collection.insert_one(record)\n",
        "\n",
        "    print(f\"Finished processing {collection_name}.\")\n",
        "\n",
        "insert_if_not_exists('cleaned_2020', cleaned_2020, 'FIPSCode')\n",
        "insert_if_not_exists('cleaned_2016', cleaned_2016, 'FIPSCode')\n",
        "\n",
        "print(\"Data successfully checked and inserted into MongoDB!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TG3AkAmzCzn",
        "outputId": "bca10f7c-7f7f-4b57-97cf-ae4a6c997ded"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished processing cleaned_2020.\n",
            "Finished processing cleaned_2016.\n",
            "Data successfully checked and inserted into MongoDB!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload to Google Cloud\n",
        "\n",
        "# Initialize a BigQuery client\n",
        "client = bigquery.Client(project='DS2002Final')\n",
        "\n",
        "# auth.authenticate_user()\n",
        "print('Authenticated')\n",
        "\n",
        "# Upload to Google Big Query\n",
        "\n",
        "cleaned_2020.to_gbq('DS2002Final.2020EAVS', project_id='ds2002final-443502', if_exists='replace')\n",
        "cleaned_2016.to_gbq('DS2002Final.2016EAVS', project_id='ds2002final-443502', if_exists='replace')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0sx3btSSMTn",
        "outputId": "89442df8-d521-4551-b203-4983c46dd9eb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-6bd7ac4d31a8>:9: FutureWarning: to_gbq is deprecated and will be removed in a future version. Please use pandas_gbq.to_gbq instead: https://pandas-gbq.readthedocs.io/en/latest/api.html#pandas_gbq.to_gbq\n",
            "  cleaned_2020.to_gbq('DS2002Final.2020EAVS', project_id='ds2002final-443502', if_exists='replace')\n",
            "100%|██████████| 1/1 [00:00<00:00, 783.40it/s]\n",
            "<ipython-input-8-6bd7ac4d31a8>:10: FutureWarning: to_gbq is deprecated and will be removed in a future version. Please use pandas_gbq.to_gbq instead: https://pandas-gbq.readthedocs.io/en/latest/api.html#pandas_gbq.to_gbq\n",
            "  cleaned_2016.to_gbq('DS2002Final.2016EAVS', project_id='ds2002final-443502', if_exists='replace')\n",
            "100%|██████████| 1/1 [00:00<00:00, 786.19it/s]\n"
          ]
        }
      ]
    }
  ]
}